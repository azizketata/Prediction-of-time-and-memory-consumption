{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9639ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      nx   ny   nz  Grid size(nx*ny*nz)  Execution time(cpu clock time)  \\\n",
      "0    10   10   10                 1000                        0.016029   \n",
      "1    20   20   20                 8000                        0.033401   \n",
      "2    30   30   30                27000                        0.130201   \n",
      "3    40   40   40                64000                        0.416461   \n",
      "4    50   50   50               125000                        0.847139   \n",
      "5    60   60   60               216000                        1.520439   \n",
      "6    70   70   70               343000                        2.620656   \n",
      "7    80   80   80               512000                        4.124697   \n",
      "8    90   90   90               729000                        5.843543   \n",
      "9   100  100  100              1000000                        7.603722   \n",
      "10  100  110  110              1210000                        9.059771   \n",
      "11  100  120  120              1440000                       12.126158   \n",
      "12  100  130  130              1690000                       13.291963   \n",
      "13  100  140  140              1960000                       15.945942   \n",
      "14  100  150  150              2250000                       19.292866   \n",
      "15  100  160  160              2560000                       22.046323   \n",
      "16  100  170  170              2890000                       26.152350   \n",
      "17  100  180  180              3240000                       28.669017   \n",
      "18  100  190  190              3610000                       31.501493   \n",
      "19  100  200  200              4000000                       34.836158   \n",
      "\n",
      "    FOM_1(figure of mertit)  \n",
      "0                  54054160  \n",
      "1                 290169800  \n",
      "2                 316247200  \n",
      "3                 264374700  \n",
      "4                 257925200  \n",
      "5                 248980000  \n",
      "6                 227961100  \n",
      "7                 230734000  \n",
      "8                 230510100  \n",
      "9                 237915300  \n",
      "10                248536400  \n",
      "11                217655000  \n",
      "12                237256200  \n",
      "13                218801700  \n",
      "14                216676000  \n",
      "15                206375700  \n",
      "16                205796700  \n",
      "17                198633400  \n",
      "18                198128400  \n",
      "19                200294200  >\n",
      "(20, 3)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "#Develop the time/memory model using the polynomial modeling approach specified by Mr Arima. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "path = r\"C:\\Users\\Aziz\\Downloads\\B.A.xlsx\"\n",
    "df = pd.read_excel(path, sheet_name=\"amg\", header=0, nrows=21, usecols=\"A:F\")\n",
    "\n",
    "# Optional: set column names\n",
    "df.columns = [\"nx\", \"ny\", \"nz\", \"Grid size(nx*ny*nz)\", \"Execution time(cpu clock time)\", \"FOM_1(figure of mertit)\"]\n",
    "df.drop([0])\n",
    "print(df.head)\n",
    "# Print the resulting DataFrame\n",
    "# Preprocessed data (arg1, arg2, arg3, memory_consumption)\n",
    "amg1_data = df.to_numpy()\n",
    "x = amg1_data[:,[0,1,2]] # Extract input parameters (arg1, arg2, arg3)\n",
    "y = amg1_data[:,4] # Extract memory consumption values\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027aae90",
   "metadata": {},
   "source": [
    "Next we work on cross validation to see which degree of the polynomial feature is best fit to our data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83d46e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# fucntion that returns the mean of the cross val scores\n",
    "def get_cross_val_score_for_degree(degree, X, y):\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    model = LinearRegression()\n",
    "    scores = cross_val_score(model, X_poly, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    return -np.mean(scores)\n",
    "\n",
    "# calculate the aic and bic of a model\n",
    "def calculate_aic_bic(degree, X, y):\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    model = LinearRegression().fit(X_poly, y)\n",
    "    y_pred = model.predict(X_poly)\n",
    "    \n",
    "    sse = np.sum((y - y_pred) ** 2)\n",
    "    k = X_poly.shape[1]  # Number of parameters\n",
    "    n = X_poly.shape[0]  # Sample size\n",
    "    \n",
    "    aic = n * np.log(sse / n) + 2 * k\n",
    "    bic = n * np.log(sse / n) + k * np.log(n)\n",
    "    \n",
    "    return aic, bic\n",
    "\n",
    "#Calculating the adjusted r squared of a model\n",
    "def get_adjusted_r_squared(degree, X, y):\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    model = LinearRegression().fit(X_poly, y)\n",
    "    y_pred = model.predict(X_poly)\n",
    "    \n",
    "    r2 = r2_score(y, y_pred)\n",
    "    n = X_poly.shape[0]  # Sample size\n",
    "    k = X_poly.shape[1] - 1  # Number of parameters (excluding intercept)\n",
    "    # n is the number of samples , k is the number of parameters if we have a small dataset then we need \n",
    "    # to add an if statement before calculating r2 to avoid dividing by 0\n",
    "    if (n - k - 1) == 0:\n",
    "        return float('-inf')\n",
    "    adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
    "    return adjusted_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59cc0bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal degree based on CV:  2\n",
      "Optimal degree based on AIC:  2\n",
      "Optimal degree based on BIC:  2\n",
      "Optimal degree based on adjusted R-squared:  4\n"
     ]
    }
   ],
   "source": [
    "# we try polynomial degrees from 1 to 5 (inclusive) and find the degree with the lowest mean squared error.\n",
    "degrees = list(range(1,6))\n",
    "cv_scores = [get_cross_val_score_for_degree(degree, x, y) for degree in degrees]\n",
    "aic_bic_scores = [calculate_aic_bic(degree, x, y) for degree in degrees]\n",
    "adjusted_r2_scores = [get_adjusted_r_squared(degree, x, y) for degree in degrees]\n",
    "aic_scores, bic_scores = zip(*aic_bic_scores)\n",
    "\n",
    "# finding the best values for our polynomial\n",
    "optimal_degree_adjusted_r2 = degrees[np.argmax(adjusted_r2_scores)]\n",
    "optimal_degree_cv = degrees[np.argmin(cv_scores)]\n",
    "optimal_degree_aic = degrees[np.argmin(aic_scores)]\n",
    "optimal_degree_bic = degrees[np.argmin(bic_scores)]\n",
    "\n",
    "print(\"Optimal degree based on CV: \", optimal_degree_cv)\n",
    "print(\"Optimal degree based on AIC: \", optimal_degree_aic)\n",
    "print(\"Optimal degree based on BIC: \", optimal_degree_bic)\n",
    "print(\"Optimal degree based on adjusted R-squared: \", optimal_degree_adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb505136",
   "metadata": {},
   "source": [
    "- we use the optimal degree to transform the input parameters, train the model, make predictions, and calculate the mean squared error.\n",
    "- The code should now find the optimal polynomial degree using cross-validation and train a model with that degree. This should result in a more accurate and robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6296b954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (optimal degree):  0.07195642433230018\n",
      "Optimal degree is:  2\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(optimal_degree_bic)\n",
    "X_train_poly_optimal = poly.fit_transform(X_train)\n",
    "X_test_poly_optimal = poly.transform(X_test)\n",
    "model = LinearRegression().fit(X_train_poly_optimal, y_train)\n",
    "y_pred_optimal = model.predict(X_test_poly_optimal)\n",
    "\n",
    "mse_optimal = np.mean((y_test - y_pred_optimal) ** 2)\n",
    "print(\"Mean squared error (optimal degree): \", mse_optimal)\n",
    "print(\"Optimal degree is: \", optimal_degree_bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb383fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
